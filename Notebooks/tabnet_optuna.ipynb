{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\My Drive\\Kaggle\\tabular-playground-series-apr-2022\\tab22\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'optuna'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mg:\\My Drive\\Kaggle\\tabular-playground-series-apr-2022\\Notebooks\\tabnet_optuna.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/tabular-playground-series-apr-2022/Notebooks/tabnet_optuna.ipynb#ch0000000?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m KFold\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/tabular-playground-series-apr-2022/Notebooks/tabnet_optuna.ipynb#ch0000000?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m roc_auc_score\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/tabular-playground-series-apr-2022/Notebooks/tabnet_optuna.ipynb#ch0000000?line=8'>9</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39moptuna\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/tabular-playground-series-apr-2022/Notebooks/tabnet_optuna.ipynb#ch0000000?line=9'>10</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39moptuna\u001b[39;00m \u001b[39mimport\u001b[39;00m Trial, visualization\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/tabular-playground-series-apr-2022/Notebooks/tabnet_optuna.ipynb#ch0000000?line=13'>14</a>\u001b[0m torch\u001b[39m.\u001b[39m__version__\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'optuna'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import optuna\n",
    "from optuna import Trial, visualization\n",
    "\n",
    "\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 11 21:50:39 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 512.15       Driver Version: 512.15       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   52C    P8     4W /  N/A |      0MiB /  6144MiB |      1%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Data/train_features_computed_tabular.csv')\n",
    "labels = pd.read_csv('../Data/train_labels.csv')\n",
    "data = data.merge(labels, on = 'sequence', how = 'left')\n",
    "X, y = data.drop(['sequence', 'state'], axis = 1).values, data['state'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "model=scaler.fit(X)\n",
    "X=model.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Objective(trial):\n",
    "    mask_type = trial.suggest_categorical(\"mask_type\", [\"entmax\", \"sparsemax\"])\n",
    "    n_da = trial.suggest_int(\"n_da\", 56, 64, step=4)\n",
    "    n_steps = trial.suggest_int(\"n_steps\", 1, 3, step=1)\n",
    "    gamma = trial.suggest_float(\"gamma\", 1., 1.4, step=0.2)\n",
    "    n_shared = trial.suggest_int(\"n_shared\", 1, 3)\n",
    "    lambda_sparse = trial.suggest_float(\"lambda_sparse\", 1e-6, 1e-3, log=True)\n",
    "    param = dict(n_d=n_da, n_a=n_da, n_steps=n_steps, gamma=gamma,\n",
    "                     lambda_sparse=lambda_sparse, optimizer_fn=torch.optim.Adam,\n",
    "                     optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n",
    "                     mask_type=mask_type, n_shared=n_shared,\n",
    "                     scheduler_params=dict(mode=\"min\",\n",
    "                                           patience=trial.suggest_int(\"patienceScheduler\",low=3,high=10), # changing sheduler patience to be lower than early stopping patience \n",
    "                                           min_lr=1e-5,\n",
    "                                           factor=0.5,),\n",
    "                     scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "                     verbose=0,\n",
    "                     ) #early stopping\n",
    "    kf = KFold(n_splits=3, random_state=42, shuffle=True)\n",
    "    CV_score_array    =[]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_valid = X[train_index], X[test_index]\n",
    "        y_train, y_valid = y[train_index], y[test_index]\n",
    "        clf = TabNetClassifier(**param)\n",
    "        clf.fit(X_train=X_train, y_train=y_train,\n",
    "                  eval_set=[(X_valid, y_valid)],\n",
    "                  patience=trial.suggest_int(\"patience\",low=15,high=30), max_epochs=trial.suggest_int('epochs', 1, 100),\n",
    "                  eval_metric=['auc'])\n",
    "        preds = clf.predict(X_valid)\n",
    "        acc = roc_auc_score(y_pred=preds, y_true=y_valid)\n",
    "\n",
    "        CV_score_array.append(acc)\n",
    "    avg = np.mean(CV_score_array)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Objective(trial):\n",
    "\n",
    "    param = {\n",
    "        'tree_method':'gpu_hist',  # this parameter means using the GPU when training our model to speedup the training process\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n",
    "        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.009,0.01,0.012,0.014,0.016,0.018, 0.02]),\n",
    "        'n_estimators': 4000,\n",
    "        'max_depth': trial.suggest_categorical('max_depth', [5,7,9,11,13,15,17,20]),\n",
    "        'random_state': trial.suggest_categorical('random_state', [24, 48,2020]),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
    "    }\n",
    "    \n",
    "    kf = KFold(n_splits=3, random_state=42, shuffle=True)\n",
    "    CV_score_array    =[]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_valid = X[train_index], X[test_index]\n",
    "        y_train, y_valid = y[train_index], y[test_index]\n",
    "        clf = xgb.XGBClassifier(**param)  \n",
    "        clf.fit(X_train=X_train, y_train=y_train,\n",
    "                  eval_set=[(X_valid, y_valid)],\n",
    "                  patience=trial.suggest_int(\"patience\",low=15,high=30),\n",
    "                  eval_metric=['auc'])\n",
    "        \n",
    "        preds = clf.predict_proba(X_valid)\n",
    "        acc = accuracy_score(y_pred=preds, y_true=y_valid)\n",
    "\n",
    "        CV_score_array.append(acc)\n",
    "    avg = np.mean(CV_score_array)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximise\", study_name='TabNet optimization')\n",
    "study.optimize(Objective, timeout=6*60) #5 hours\n",
    "\n",
    "best = study.best_params\n",
    "print('The best parameters are ', best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_params = dict(\n",
    "    n_d=best[\"n_da\"],\n",
    "    n_a=best[\"n_da\"],\n",
    "    n_steps=best[\"n_steps\"],\n",
    "    gamma=best[\"gamma\"],\n",
    "    lambda_sparse=best[\"lambda_sparse\"],\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n",
    "    mask_type=best[\"mask_type\"],\n",
    "    n_shared=best[\"n_shared\"],\n",
    "    scheduler_params=dict(\n",
    "        mode=\"min\",\n",
    "        patience=best[\"patienceScheduler\"],\n",
    "        min_lr=1e-5,\n",
    "        factor=0.5,\n",
    "    ),\n",
    "    scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    verbose=0,\n",
    ")\n",
    "epochs = best[\"epochs\"]\n",
    "\n",
    "clf = TabNetClassifier(**best_model_params)\n",
    "clf.fit(X_train=X, y_train=y,\n",
    "          patience=best['patience'], max_epochs=epochs,\n",
    "          eval_metric=['auc'])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f0328b9ad2d19e2d019a5993aa83b306c7898874533c9685774e41d7ccadc38f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 ('tab22': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
