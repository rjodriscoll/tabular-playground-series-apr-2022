{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0+cu113'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import optuna\n",
    "from optuna import Trial, visualization\n",
    "\n",
    "\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 21 11:16:11 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 512.15       Driver Version: 512.15       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   50C    P8     4W /  N/A |      0MiB /  6144MiB |      1%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      8188      C   ...ython\\Python39\\python.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Data/train_features_computed_tabular.csv')\n",
    "labels = pd.read_csv('../Data/train_labels.csv')\n",
    "data = data.merge(labels, on = 'sequence', how = 'left')\n",
    "X, y = data.drop(['sequence', 'state'], axis = 1).values, data['state'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "model=scaler.fit(X)\n",
    "X=model.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Objective(trial):\n",
    "    mask_type = trial.suggest_categorical(\"mask_type\", [\"entmax\", \"sparsemax\"])\n",
    "    n_da = trial.suggest_int(\"n_da\", 56, 64, step=4)\n",
    "    n_steps = trial.suggest_int(\"n_steps\", 1, 3, step=1)\n",
    "    gamma = trial.suggest_float(\"gamma\", 1.0, 1.4, step=0.2)\n",
    "    n_shared = trial.suggest_int(\"n_shared\", 1, 3)\n",
    "    lambda_sparse = trial.suggest_float(\"lambda_sparse\", 1e-6, 1e-3, log=True)\n",
    "    param = dict(\n",
    "        n_d=n_da,\n",
    "        n_a=n_da,\n",
    "        n_steps=n_steps,\n",
    "        gamma=gamma,\n",
    "        lambda_sparse=lambda_sparse,\n",
    "        optimizer_fn=torch.optim.Adam,\n",
    "        optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n",
    "        mask_type=mask_type,\n",
    "        n_shared=n_shared,\n",
    "        scheduler_params=dict(\n",
    "            mode=\"min\",\n",
    "            patience=trial.suggest_int(\"patienceScheduler\", low=3, high=10),\n",
    "            min_lr=1e-5,\n",
    "            factor=0.5,\n",
    "        ),\n",
    "        scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "        verbose=0,\n",
    "    )\n",
    "    kf = KFold(n_splits=3, random_state=42, shuffle=True)\n",
    "    CV_score_array = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_valid = X[train_index], X[test_index]\n",
    "        y_train, y_valid = y[train_index], y[test_index]\n",
    "        clf = TabNetClassifier(**param)\n",
    "        clf.fit(\n",
    "            X_train=X_train,\n",
    "            y_train=y_train,\n",
    "            eval_set=[(X_valid, y_valid)],\n",
    "            patience=trial.suggest_int(\"patience\", low=15, high=30),\n",
    "            max_epochs=trial.suggest_int(\"epochs\", 1, 100),\n",
    "        )\n",
    "        preds = clf.predict(X_valid)\n",
    "        auc = roc_auc_score(y_valid, preds)\n",
    "\n",
    "        CV_score_array.append(auc)\n",
    "    avg = np.mean(CV_score_array)\n",
    "    return avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-21 11:16:30,573]\u001b[0m A new study created in memory with name: TabNet optimization\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 8 with best_epoch = 7 and best_val_0_auc = 0.83962\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 8 with best_epoch = 7 and best_val_0_auc = 0.84173\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 8 with best_epoch = 7 and best_val_0_auc = 0.83231\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-21 11:17:21,571]\u001b[0m Trial 0 finished with value: 0.7675103777093201 and parameters: {'mask_type': 'sparsemax', 'n_da': 56, 'n_steps': 2, 'gamma': 1.2, 'n_shared': 3, 'lambda_sparse': 9.271707091323517e-06, 'patienceScheduler': 9, 'patience': 17, 'epochs': 8}. Best is trial 0 with value: 0.7675103777093201.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 14 and best_val_0_auc = 0.86183\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 14 and best_val_0_auc = 0.87259\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 19 and best_val_0_auc = 0.86842\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-21 11:19:20,644]\u001b[0m Trial 1 finished with value: 0.7924097928755233 and parameters: {'mask_type': 'entmax', 'n_da': 60, 'n_steps': 1, 'gamma': 1.0, 'n_shared': 2, 'lambda_sparse': 0.0002052578825220565, 'patienceScheduler': 5, 'patience': 16, 'epochs': 99}. Best is trial 1 with value: 0.7924097928755233.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 37 with best_epoch = 13 and best_val_0_auc = 0.86441\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 11 and best_val_0_auc = 0.87056\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 12 and best_val_0_auc = 0.86137\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-21 11:21:21,278]\u001b[0m Trial 2 finished with value: 0.7912998177671828 and parameters: {'mask_type': 'entmax', 'n_da': 64, 'n_steps': 1, 'gamma': 1.2, 'n_shared': 1, 'lambda_sparse': 0.0007776235991341509, 'patienceScheduler': 9, 'patience': 24, 'epochs': 37}. Best is trial 1 with value: 0.7924097928755233.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 40 with best_epoch = 23 and best_val_0_auc = 0.86637\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 40 with best_epoch = 21 and best_val_0_auc = 0.86728\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_val_0_auc = 0.85917\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-21 11:24:00,037]\u001b[0m Trial 3 finished with value: 0.7897864020056652 and parameters: {'mask_type': 'sparsemax', 'n_da': 60, 'n_steps': 1, 'gamma': 1.0, 'n_shared': 2, 'lambda_sparse': 0.00035600368131822626, 'patienceScheduler': 6, 'patience': 20, 'epochs': 40}. Best is trial 1 with value: 0.7924097928755233.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are  {'mask_type': 'entmax', 'n_da': 60, 'n_steps': 1, 'gamma': 1.0, 'n_shared': 2, 'lambda_sparse': 0.0002052578825220565, 'patienceScheduler': 5, 'patience': 16, 'epochs': 99}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\", study_name='TabNet optimization')\n",
    "study.optimize(Objective, timeout=6*60) #5 hours\n",
    "\n",
    "best = study.best_params\n",
    "print('The best parameters are ', best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No early stopping will be performed, last training weights will be used.\n"
     ]
    }
   ],
   "source": [
    "best_model_params = dict(\n",
    "    n_d=best[\"n_da\"],\n",
    "    n_a=best[\"n_da\"],\n",
    "    n_steps=best[\"n_steps\"],\n",
    "    gamma=best[\"gamma\"],\n",
    "    lambda_sparse=best[\"lambda_sparse\"],\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n",
    "    mask_type=best[\"mask_type\"],\n",
    "    n_shared=best[\"n_shared\"],\n",
    "    scheduler_params=dict(\n",
    "        mode=\"min\",\n",
    "        patience=best[\"patienceScheduler\"],\n",
    "        min_lr=1e-5,\n",
    "        factor=0.5,\n",
    "    ),\n",
    "    scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    verbose=0,\n",
    ")\n",
    "epochs = best[\"epochs\"]\n",
    "\n",
    "clf = TabNetClassifier(**best_model_params)\n",
    "clf.fit(X_train=X, y_train=y,\n",
    "          patience=best['patience'], max_epochs=epochs,\n",
    "          eval_metric=['auc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../Data/test_features_computed_tabular.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop('sequence', axis = 1, inplace = True)\n",
    "test = model.transform(np.array(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('../Data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['state'] = preds\n",
    "sub.to_csv('../Submissions/tabnet_sub.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6352\n",
       "0    5866\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.state.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25968</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25969</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25970</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25971</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25972</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12213</th>\n",
       "      <td>38181</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12214</th>\n",
       "      <td>38182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12215</th>\n",
       "      <td>38183</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12216</th>\n",
       "      <td>38184</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12217</th>\n",
       "      <td>38185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12218 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sequence  state\n",
       "0         25968      0\n",
       "1         25969      1\n",
       "2         25970      0\n",
       "3         25971      0\n",
       "4         25972      1\n",
       "...         ...    ...\n",
       "12213     38181      0\n",
       "12214     38182      0\n",
       "12215     38183      1\n",
       "12216     38184      0\n",
       "12217     38185      0\n",
       "\n",
       "[12218 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f0328b9ad2d19e2d019a5993aa83b306c7898874533c9685774e41d7ccadc38f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 ('tab22': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
