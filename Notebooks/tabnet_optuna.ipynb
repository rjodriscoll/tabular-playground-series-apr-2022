{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\My Drive\\Kaggle\\tabular-playground-series-apr-2022\\tab22\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.10.1+cu113'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import optuna\n",
    "from optuna import Trial, visualization\n",
    "\n",
    "\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr 12 09:02:38 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 496.13       Driver Version: 496.13       CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   39C    P5    20W / 250W |    938MiB /  8192MiB |      2%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1340    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A      1928    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A      5900    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A      6304    C+G   ...zilla Firefox\\firefox.exe    N/A      |\n",
      "|    0   N/A  N/A      7648    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A      8316    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
      "|    0   N/A  N/A      8792    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A      9832    C+G   ...zilla Firefox\\firefox.exe    N/A      |\n",
      "|    0   N/A  N/A     11400    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     12796    C+G   ....0.11.0\\GoogleDriveFS.exe    N/A      |\n",
      "|    0   N/A  N/A     13516    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     13796    C+G   ...p-2.9.6\\GitHubDesktop.exe    N/A      |\n",
      "|    0   N/A  N/A     16876    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     17744    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Data/train_features_computed_tabular.csv')\n",
    "labels = pd.read_csv('../Data/train_labels.csv')\n",
    "data = data.merge(labels, on = 'sequence', how = 'left')\n",
    "X, y = data.drop(['sequence', 'state'], axis = 1).values, data['state'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "model=scaler.fit(X)\n",
    "X=model.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Objective(trial):\n",
    "    mask_type = trial.suggest_categorical(\"mask_type\", [\"entmax\", \"sparsemax\"])\n",
    "    n_da = trial.suggest_int(\"n_da\", 56, 64, step=4)\n",
    "    n_steps = trial.suggest_int(\"n_steps\", 1, 3, step=1)\n",
    "    gamma = trial.suggest_float(\"gamma\", 1.0, 1.4, step=0.2)\n",
    "    n_shared = trial.suggest_int(\"n_shared\", 1, 3)\n",
    "    lambda_sparse = trial.suggest_float(\"lambda_sparse\", 1e-6, 1e-3, log=True)\n",
    "    param = dict(\n",
    "        n_d=n_da,\n",
    "        n_a=n_da,\n",
    "        n_steps=n_steps,\n",
    "        gamma=gamma,\n",
    "        lambda_sparse=lambda_sparse,\n",
    "        optimizer_fn=torch.optim.Adam,\n",
    "        optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n",
    "        mask_type=mask_type,\n",
    "        n_shared=n_shared,\n",
    "        scheduler_params=dict(\n",
    "            mode=\"min\",\n",
    "            patience=trial.suggest_int(\"patienceScheduler\", low=3, high=10),\n",
    "            min_lr=1e-5,\n",
    "            factor=0.5,\n",
    "        ),\n",
    "        scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "        verbose=0,\n",
    "    )\n",
    "    kf = KFold(n_splits=3, random_state=42, shuffle=True)\n",
    "    CV_score_array = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_valid = X[train_index], X[test_index]\n",
    "        y_train, y_valid = y[train_index], y[test_index]\n",
    "        clf = TabNetClassifier(**param)\n",
    "        clf.fit(\n",
    "            X_train=X_train,\n",
    "            y_train=y_train,\n",
    "            eval_set=[(X_valid, y_valid)],\n",
    "            patience=trial.suggest_int(\"patience\", low=15, high=30),\n",
    "            max_epochs=trial.suggest_int(\"epochs\", 1, 100),\n",
    "        )\n",
    "        preds = clf.predict(X_valid)\n",
    "        auc = roc_auc_score(y_valid, preds)\n",
    "\n",
    "        CV_score_array.append(auc)\n",
    "    avg = np.mean(CV_score_array)\n",
    "    return avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-12 09:02:40,017]\u001b[0m A new study created in memory with name: TabNet optimization\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 36 with best_epoch = 24 and best_val_0_auc = 0.87029\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 36 with best_epoch = 27 and best_val_0_auc = 0.87781\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 36 with best_epoch = 27 and best_val_0_auc = 0.86642\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-12 09:04:28,231]\u001b[0m Trial 0 finished with value: 0.7918052503059556 and parameters: {'mask_type': 'entmax', 'n_da': 64, 'n_steps': 3, 'gamma': 1.2, 'n_shared': 3, 'lambda_sparse': 0.00023593938579518834, 'patienceScheduler': 8, 'patience': 17, 'epochs': 36}. Best is trial 0 with value: 0.7918052503059556.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 2 with best_epoch = 1 and best_val_0_auc = 0.8251\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 2 with best_epoch = 1 and best_val_0_auc = 0.82409\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 2 with best_epoch = 1 and best_val_0_auc = 0.82288\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-12 09:04:32,012]\u001b[0m Trial 1 finished with value: 0.7579470838729235 and parameters: {'mask_type': 'entmax', 'n_da': 60, 'n_steps': 1, 'gamma': 1.2, 'n_shared': 2, 'lambda_sparse': 0.0001773258467273771, 'patienceScheduler': 6, 'patience': 19, 'epochs': 2}. Best is trial 0 with value: 0.7918052503059556.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 11 with best_epoch = 9 and best_val_0_auc = 0.86574\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 11 with best_epoch = 10 and best_val_0_auc = 0.86168\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 11 with best_epoch = 9 and best_val_0_auc = 0.85916\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-12 09:04:50,058]\u001b[0m Trial 2 finished with value: 0.7859581403985431 and parameters: {'mask_type': 'entmax', 'n_da': 60, 'n_steps': 1, 'gamma': 1.0, 'n_shared': 3, 'lambda_sparse': 1.3653923328920348e-06, 'patienceScheduler': 6, 'patience': 21, 'epochs': 11}. Best is trial 0 with value: 0.7918052503059556.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 62 with best_epoch = 57 and best_val_0_auc = 0.87391\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 52 with best_epoch = 23 and best_val_0_auc = 0.87596\n",
      "Best weights from best epoch are automatically used!\n",
      "Stop training because you reached max_epochs = 62 with best_epoch = 55 and best_val_0_auc = 0.87098\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-12 09:07:00,427]\u001b[0m Trial 3 finished with value: 0.793408361234848 and parameters: {'mask_type': 'entmax', 'n_da': 56, 'n_steps': 2, 'gamma': 1.0, 'n_shared': 3, 'lambda_sparse': 2.5693078926127237e-05, 'patienceScheduler': 6, 'patience': 29, 'epochs': 62}. Best is trial 3 with value: 0.793408361234848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 57 with best_epoch = 39 and best_val_0_auc = 0.83273\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 77 with best_epoch = 59 and best_val_0_auc = 0.84699\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 63 with best_epoch = 45 and best_val_0_auc = 0.84083\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-12 09:09:46,573]\u001b[0m Trial 4 finished with value: 0.7667660875603742 and parameters: {'mask_type': 'sparsemax', 'n_da': 60, 'n_steps': 3, 'gamma': 1.0, 'n_shared': 2, 'lambda_sparse': 2.2050446144967754e-06, 'patienceScheduler': 3, 'patience': 18, 'epochs': 97}. Best is trial 3 with value: 0.793408361234848.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are  {'mask_type': 'entmax', 'n_da': 56, 'n_steps': 2, 'gamma': 1.0, 'n_shared': 3, 'lambda_sparse': 2.5693078926127237e-05, 'patienceScheduler': 6, 'patience': 29, 'epochs': 62}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\", study_name='TabNet optimization')\n",
    "study.optimize(Objective, timeout=6*60) #5 hours\n",
    "\n",
    "best = study.best_params\n",
    "print('The best parameters are ', best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mg:\\My Drive\\Kaggle\\tabular-playground-series-apr-2022\\Notebooks\\tabnet_optuna.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/tabular-playground-series-apr-2022/Notebooks/tabnet_optuna.ipynb#ch0000007?line=0'>1</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39m# not run \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/tabular-playground-series-apr-2022/Notebooks/tabnet_optuna.ipynb#ch0000007?line=1'>2</a>\u001b[0m best_model_params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/tabular-playground-series-apr-2022/Notebooks/tabnet_optuna.ipynb#ch0000007?line=2'>3</a>\u001b[0m     n_d\u001b[39m=\u001b[39mbest[\u001b[39m\"\u001b[39m\u001b[39mn_da\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/tabular-playground-series-apr-2022/Notebooks/tabnet_optuna.ipynb#ch0000007?line=3'>4</a>\u001b[0m     n_a\u001b[39m=\u001b[39mbest[\u001b[39m\"\u001b[39m\u001b[39mn_da\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/tabular-playground-series-apr-2022/Notebooks/tabnet_optuna.ipynb#ch0000007?line=18'>19</a>\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/tabular-playground-series-apr-2022/Notebooks/tabnet_optuna.ipynb#ch0000007?line=19'>20</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Kaggle/tabular-playground-series-apr-2022/Notebooks/tabnet_optuna.ipynb#ch0000007?line=20'>21</a>\u001b[0m epochs \u001b[39m=\u001b[39m best[\u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False # not run \n",
    "best_model_params = dict(\n",
    "    n_d=best[\"n_da\"],\n",
    "    n_a=best[\"n_da\"],\n",
    "    n_steps=best[\"n_steps\"],\n",
    "    gamma=best[\"gamma\"],\n",
    "    lambda_sparse=best[\"lambda_sparse\"],\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n",
    "    mask_type=best[\"mask_type\"],\n",
    "    n_shared=best[\"n_shared\"],\n",
    "    scheduler_params=dict(\n",
    "        mode=\"min\",\n",
    "        patience=best[\"patienceScheduler\"],\n",
    "        min_lr=1e-5,\n",
    "        factor=0.5,\n",
    "    ),\n",
    "    scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    verbose=0,\n",
    ")\n",
    "epochs = best[\"epochs\"]\n",
    "\n",
    "clf = TabNetClassifier(**best_model_params)\n",
    "clf.fit(X_train=X, y_train=y,\n",
    "          patience=best['patience'], max_epochs=epochs,\n",
    "          eval_metric=['auc'])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f0328b9ad2d19e2d019a5993aa83b306c7898874533c9685774e41d7ccadc38f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 ('tab22': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
