{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from utility_funcs import get_train_labels_test, split_train_data, scale_and_as_array\n",
    "\n",
    "import random \n",
    "\n",
    "random.seed(42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train, labels, test = get_train_labels_test(is_py=False)\n",
    "\n",
    "features = [f for f in train.columns if \"sensor\" in f]\n",
    "\n",
    "groups = train[\"sequence\"]\n",
    "train = train.drop([\"sequence\", \"subject\", \"step\"], axis=1).values\n",
    "test = test.drop([\"sequence\", \"subject\", \"step\"], axis=1).values\n",
    "labels = labels[\"state\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train = scaler.fit_transform(train)\n",
    "test = scaler.transform(test)\n",
    "\n",
    "\n",
    "train = train.reshape(-1, 60, 13)\n",
    "test = test.reshape(-1, 60, 13)\n",
    "\n",
    "assert train.shape[0] == labels.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RNN_model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 60, 1024)         2154496   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 60, 512)          2623488   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 60, 256)          656384    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 60, 128)          164352    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 60, 64)           31104     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3840)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 200)               768200    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 150)               30150     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                7550      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,435,775\n",
      "Trainable params: 6,435,775\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Fitting fold 0 for RNN_model_6...\n",
      "Epoch 1/100\n",
      "163/163 [==============================] - 40s 167ms/step - loss: 0.6343 - auc: 0.6917 - val_loss: 0.5076 - val_auc: 0.8344\n",
      "Epoch 2/100\n",
      "163/163 [==============================] - 26s 161ms/step - loss: 0.5006 - auc: 0.8366 - val_loss: 0.4098 - val_auc: 0.8975\n",
      "Epoch 3/100\n",
      "163/163 [==============================] - 26s 161ms/step - loss: 0.4049 - auc: 0.8971 - val_loss: 0.3764 - val_auc: 0.9194\n",
      "Epoch 4/100\n",
      "163/163 [==============================] - 26s 161ms/step - loss: 0.3376 - auc: 0.9297 - val_loss: 0.3431 - val_auc: 0.9316\n",
      "Epoch 5/100\n",
      "163/163 [==============================] - 26s 160ms/step - loss: 0.2955 - auc: 0.9465 - val_loss: 0.2899 - val_auc: 0.9500\n",
      "Epoch 6/100\n",
      "163/163 [==============================] - 26s 160ms/step - loss: 0.2687 - auc: 0.9560 - val_loss: 0.2834 - val_auc: 0.9513\n",
      "Epoch 7/100\n",
      "163/163 [==============================] - 26s 161ms/step - loss: 0.2413 - auc: 0.9645 - val_loss: 0.3011 - val_auc: 0.9502\n",
      "Epoch 8/100\n",
      "163/163 [==============================] - 26s 160ms/step - loss: 0.2274 - auc: 0.9683 - val_loss: 0.2772 - val_auc: 0.9572\n",
      "Epoch 9/100\n",
      "163/163 [==============================] - 26s 157ms/step - loss: 0.2097 - auc: 0.9731 - val_loss: 0.2662 - val_auc: 0.9582\n",
      "Epoch 10/100\n",
      "163/163 [==============================] - 25s 155ms/step - loss: 0.1911 - auc: 0.9775 - val_loss: 0.2801 - val_auc: 0.9566\n",
      "Epoch 11/100\n",
      "163/163 [==============================] - 26s 162ms/step - loss: 0.1666 - auc: 0.9827 - val_loss: 0.2911 - val_auc: 0.9537\n",
      "Epoch 12/100\n",
      "163/163 [==============================] - 26s 159ms/step - loss: 0.1527 - auc: 0.9853 - val_loss: 0.2863 - val_auc: 0.9577\n",
      "Epoch 13/100\n",
      "163/163 [==============================] - 26s 158ms/step - loss: 0.1423 - auc: 0.9873 - val_loss: 0.2991 - val_auc: 0.9563\n",
      "Epoch 14/100\n",
      "163/163 [==============================] - 26s 158ms/step - loss: 0.1198 - auc: 0.9907 - val_loss: 0.3239 - val_auc: 0.9523\n",
      "Epoch 15/100\n",
      "163/163 [==============================] - 26s 158ms/step - loss: 0.1106 - auc: 0.9922 - val_loss: 0.3195 - val_auc: 0.9547\n",
      "Epoch 16/100\n",
      "163/163 [==============================] - 26s 158ms/step - loss: 0.0958 - auc: 0.9941 - val_loss: 0.3653 - val_auc: 0.9518\n",
      "Epoch 17/100\n",
      "163/163 [==============================] - 26s 159ms/step - loss: 0.0860 - auc: 0.9949 - val_loss: 0.3892 - val_auc: 0.9466\n",
      "Epoch 18/100\n",
      "163/163 [==============================] - 26s 158ms/step - loss: 0.0719 - auc: 0.9965 - val_loss: 0.3584 - val_auc: 0.9540\n",
      "Epoch 19/100\n",
      "163/163 [==============================] - 26s 158ms/step - loss: 0.0661 - auc: 0.9967 - val_loss: 0.4642 - val_auc: 0.9428\n",
      "The val auc for fold 0, RNN_model_6 is 0.9583803574699593\n",
      "Fitting fold 1 for RNN_model_6...\n",
      "Epoch 1/100\n",
      "163/163 [==============================] - 36s 168ms/step - loss: 0.6324 - auc_1: 0.6970 - val_loss: 0.5506 - val_auc_1: 0.8180\n",
      "Epoch 2/100\n",
      "163/163 [==============================] - 26s 160ms/step - loss: 0.4811 - auc_1: 0.8493 - val_loss: 0.4577 - val_auc_1: 0.8788\n",
      "Epoch 3/100\n",
      "163/163 [==============================] - 26s 160ms/step - loss: 0.3950 - auc_1: 0.9023 - val_loss: 0.3653 - val_auc_1: 0.9188\n",
      "Epoch 4/100\n",
      "163/163 [==============================] - 24s 149ms/step - loss: 0.3360 - auc_1: 0.9304 - val_loss: 0.4159 - val_auc_1: 0.9314\n",
      "Epoch 5/100\n",
      "163/163 [==============================] - 24s 147ms/step - loss: 0.2918 - auc_1: 0.9480 - val_loss: 0.2972 - val_auc_1: 0.9495\n",
      "Epoch 6/100\n",
      "163/163 [==============================] - 24s 149ms/step - loss: 0.2617 - auc_1: 0.9583 - val_loss: 0.2770 - val_auc_1: 0.9547\n",
      "Epoch 7/100\n",
      "163/163 [==============================] - 23s 142ms/step - loss: 0.2419 - auc_1: 0.9642 - val_loss: 0.2721 - val_auc_1: 0.9570\n",
      "Epoch 8/100\n",
      "163/163 [==============================] - 23s 141ms/step - loss: 0.2168 - auc_1: 0.9712 - val_loss: 0.2666 - val_auc_1: 0.9584\n",
      "Epoch 9/100\n",
      "163/163 [==============================] - 23s 141ms/step - loss: 0.1968 - auc_1: 0.9762 - val_loss: 0.2932 - val_auc_1: 0.9483\n",
      "Epoch 10/100\n",
      "163/163 [==============================] - 23s 141ms/step - loss: 0.1867 - auc_1: 0.9785 - val_loss: 0.2702 - val_auc_1: 0.9566\n",
      "Epoch 11/100\n",
      "163/163 [==============================] - 23s 141ms/step - loss: 0.1722 - auc_1: 0.9815 - val_loss: 0.2871 - val_auc_1: 0.9598\n",
      "Epoch 12/100\n",
      "163/163 [==============================] - 23s 141ms/step - loss: 0.1462 - auc_1: 0.9865 - val_loss: 0.2793 - val_auc_1: 0.9608\n",
      "Epoch 13/100\n",
      "163/163 [==============================] - 22s 138ms/step - loss: 0.1361 - auc_1: 0.9882 - val_loss: 0.3197 - val_auc_1: 0.9558\n",
      "Epoch 14/100\n",
      "163/163 [==============================] - 23s 142ms/step - loss: 0.1198 - auc_1: 0.9909 - val_loss: 0.3012 - val_auc_1: 0.9595\n",
      "Epoch 15/100\n",
      "163/163 [==============================] - 24s 147ms/step - loss: 0.1062 - auc_1: 0.9928 - val_loss: 0.2980 - val_auc_1: 0.9558\n",
      "Epoch 16/100\n",
      "163/163 [==============================] - 24s 147ms/step - loss: 0.0942 - auc_1: 0.9941 - val_loss: 0.3460 - val_auc_1: 0.9527\n",
      "Epoch 17/100\n",
      "163/163 [==============================] - 23s 141ms/step - loss: 0.0816 - auc_1: 0.9955 - val_loss: 0.3451 - val_auc_1: 0.9534\n",
      "Epoch 18/100\n",
      "163/163 [==============================] - 24s 147ms/step - loss: 0.0670 - auc_1: 0.9968 - val_loss: 0.3707 - val_auc_1: 0.9506\n",
      "The val auc for fold 1, RNN_model_6 is 0.9585533324001537\n",
      "Fitting fold 2 for RNN_model_6...\n",
      "Epoch 1/100\n",
      "163/163 [==============================] - 32s 143ms/step - loss: 0.6116 - auc_2: 0.7263 - val_loss: 0.5231 - val_auc_2: 0.8235\n",
      "Epoch 2/100\n",
      "163/163 [==============================] - 22s 135ms/step - loss: 0.4696 - auc_2: 0.8585 - val_loss: 0.4171 - val_auc_2: 0.8952\n",
      "Epoch 3/100\n",
      "163/163 [==============================] - 23s 143ms/step - loss: 0.3826 - auc_2: 0.9089 - val_loss: 0.3632 - val_auc_2: 0.9263\n",
      "Epoch 4/100\n",
      "163/163 [==============================] - 23s 142ms/step - loss: 0.3289 - auc_2: 0.9335 - val_loss: 0.3207 - val_auc_2: 0.9378\n",
      "Epoch 5/100\n",
      "163/163 [==============================] - 22s 134ms/step - loss: 0.2948 - auc_2: 0.9469 - val_loss: 0.3174 - val_auc_2: 0.9411\n",
      "Epoch 6/100\n",
      "163/163 [==============================] - 22s 134ms/step - loss: 0.2717 - auc_2: 0.9548 - val_loss: 0.3480 - val_auc_2: 0.9459\n",
      "Epoch 7/100\n",
      "163/163 [==============================] - 23s 138ms/step - loss: 0.2486 - auc_2: 0.9623 - val_loss: 0.2956 - val_auc_2: 0.9478\n",
      "Epoch 8/100\n",
      "163/163 [==============================] - 22s 134ms/step - loss: 0.2375 - auc_2: 0.9656 - val_loss: 0.3406 - val_auc_2: 0.9381\n",
      "Epoch 9/100\n",
      "163/163 [==============================] - 21s 128ms/step - loss: 0.2175 - auc_2: 0.9710 - val_loss: 0.2892 - val_auc_2: 0.9524\n",
      "Epoch 10/100\n",
      "163/163 [==============================] - 22s 132ms/step - loss: 0.2009 - auc_2: 0.9752 - val_loss: 0.3279 - val_auc_2: 0.9520\n",
      "Epoch 11/100\n",
      "163/163 [==============================] - 22s 132ms/step - loss: 0.1853 - auc_2: 0.9788 - val_loss: 0.3164 - val_auc_2: 0.9464\n",
      "Epoch 12/100\n",
      "163/163 [==============================] - 20s 122ms/step - loss: 0.1599 - auc_2: 0.9841 - val_loss: 0.3369 - val_auc_2: 0.9491\n",
      "Epoch 13/100\n",
      "163/163 [==============================] - 20s 121ms/step - loss: 0.1371 - auc_2: 0.9882 - val_loss: 0.3462 - val_auc_2: 0.9468\n",
      "Epoch 14/100\n",
      "163/163 [==============================] - 20s 121ms/step - loss: 0.1260 - auc_2: 0.9900 - val_loss: 0.3878 - val_auc_2: 0.9445\n",
      "Epoch 15/100\n",
      "163/163 [==============================] - 20s 121ms/step - loss: 0.1068 - auc_2: 0.9926 - val_loss: 0.3683 - val_auc_2: 0.9471\n",
      "Epoch 16/100\n",
      "163/163 [==============================] - 21s 131ms/step - loss: 0.0934 - auc_2: 0.9943 - val_loss: 0.4654 - val_auc_2: 0.9361\n",
      "Epoch 17/100\n",
      "163/163 [==============================] - 21s 128ms/step - loss: 0.0907 - auc_2: 0.9943 - val_loss: 0.4175 - val_auc_2: 0.9415\n",
      "Epoch 18/100\n",
      "163/163 [==============================] - 23s 139ms/step - loss: 0.0772 - auc_2: 0.9959 - val_loss: 0.4404 - val_auc_2: 0.9401\n",
      "Epoch 19/100\n",
      "163/163 [==============================] - 21s 127ms/step - loss: 0.0714 - auc_2: 0.9964 - val_loss: 0.4334 - val_auc_2: 0.9374\n",
      "The val auc for fold 2, RNN_model_6 is 0.9525907036135546\n",
      "Fitting fold 3 for RNN_model_6...\n",
      "Epoch 1/100\n",
      "163/163 [==============================] - 31s 139ms/step - loss: 0.6344 - auc_3: 0.6918 - val_loss: 0.5167 - val_auc_3: 0.8359\n",
      "Epoch 2/100\n",
      "163/163 [==============================] - 20s 123ms/step - loss: 0.4698 - auc_3: 0.8582 - val_loss: 0.4041 - val_auc_3: 0.9040\n",
      "Epoch 3/100\n",
      "163/163 [==============================] - 20s 123ms/step - loss: 0.3781 - auc_3: 0.9111 - val_loss: 0.3406 - val_auc_3: 0.9323\n",
      "Epoch 4/100\n",
      "163/163 [==============================] - 21s 126ms/step - loss: 0.3295 - auc_3: 0.9332 - val_loss: 0.3281 - val_auc_3: 0.9385\n",
      "Epoch 5/100\n",
      "163/163 [==============================] - 21s 132ms/step - loss: 0.2931 - auc_3: 0.9475 - val_loss: 0.3171 - val_auc_3: 0.9412\n",
      "Epoch 6/100\n",
      "163/163 [==============================] - 21s 131ms/step - loss: 0.2685 - auc_3: 0.9560 - val_loss: 0.3507 - val_auc_3: 0.9436\n",
      "Epoch 7/100\n",
      "163/163 [==============================] - 21s 128ms/step - loss: 0.2519 - auc_3: 0.9613 - val_loss: 0.3035 - val_auc_3: 0.9467\n",
      "Epoch 8/100\n",
      "163/163 [==============================] - 20s 121ms/step - loss: 0.2200 - auc_3: 0.9704 - val_loss: 0.2896 - val_auc_3: 0.9496\n",
      "Epoch 9/100\n",
      "163/163 [==============================] - 20s 121ms/step - loss: 0.2026 - auc_3: 0.9748 - val_loss: 0.2978 - val_auc_3: 0.9492\n",
      "Epoch 10/100\n",
      "163/163 [==============================] - 20s 122ms/step - loss: 0.1940 - auc_3: 0.9769 - val_loss: 0.2919 - val_auc_3: 0.9556\n",
      "Epoch 11/100\n",
      "163/163 [==============================] - 20s 125ms/step - loss: 0.1764 - auc_3: 0.9808 - val_loss: 0.2974 - val_auc_3: 0.9526\n",
      "Epoch 12/100\n",
      "163/163 [==============================] - 20s 121ms/step - loss: 0.1594 - auc_3: 0.9842 - val_loss: 0.3122 - val_auc_3: 0.9549\n",
      "Epoch 13/100\n",
      "163/163 [==============================] - 20s 121ms/step - loss: 0.1371 - auc_3: 0.9881 - val_loss: 0.3156 - val_auc_3: 0.9539\n",
      "Epoch 14/100\n",
      "163/163 [==============================] - 21s 132ms/step - loss: 0.1278 - auc_3: 0.9896 - val_loss: 0.3349 - val_auc_3: 0.9484\n",
      "Epoch 15/100\n",
      "163/163 [==============================] - 22s 135ms/step - loss: 0.1085 - auc_3: 0.9922 - val_loss: 0.3901 - val_auc_3: 0.9447\n",
      "Epoch 16/100\n",
      "163/163 [==============================] - 23s 142ms/step - loss: 0.1049 - auc_3: 0.9929 - val_loss: 0.3932 - val_auc_3: 0.9464\n",
      "Epoch 17/100\n",
      "163/163 [==============================] - 24s 147ms/step - loss: 0.0895 - auc_3: 0.9947 - val_loss: 0.4111 - val_auc_3: 0.9460\n",
      "Epoch 18/100\n",
      "163/163 [==============================] - 23s 142ms/step - loss: 0.0857 - auc_3: 0.9950 - val_loss: 0.3687 - val_auc_3: 0.9486\n",
      "The val auc for fold 3, RNN_model_6 is 0.9496726232065035\n",
      "Fitting fold 4 for RNN_model_6...\n",
      "Epoch 1/100\n",
      "163/163 [==============================] - 34s 156ms/step - loss: 0.6030 - auc_4: 0.7349 - val_loss: 0.5277 - val_auc_4: 0.8266\n",
      "Epoch 2/100\n",
      "163/163 [==============================] - 24s 147ms/step - loss: 0.4365 - auc_4: 0.8790 - val_loss: 0.4178 - val_auc_4: 0.8962\n",
      "Epoch 3/100\n",
      "163/163 [==============================] - 24s 147ms/step - loss: 0.3519 - auc_4: 0.9237 - val_loss: 0.3392 - val_auc_4: 0.9295\n",
      "Epoch 4/100\n",
      "163/163 [==============================] - 24s 148ms/step - loss: 0.3070 - auc_4: 0.9422 - val_loss: 0.3018 - val_auc_4: 0.9444\n",
      "Epoch 5/100\n",
      "163/163 [==============================] - 24s 147ms/step - loss: 0.2875 - auc_4: 0.9494 - val_loss: 0.3213 - val_auc_4: 0.9435\n",
      "Epoch 6/100\n",
      "163/163 [==============================] - 24s 147ms/step - loss: 0.2617 - auc_4: 0.9582 - val_loss: 0.3027 - val_auc_4: 0.9513\n",
      "Epoch 7/100\n",
      "163/163 [==============================] - 24s 147ms/step - loss: 0.2357 - auc_4: 0.9660 - val_loss: 0.3074 - val_auc_4: 0.9543\n",
      "Epoch 8/100\n",
      "163/163 [==============================] - 24s 148ms/step - loss: 0.2128 - auc_4: 0.9724 - val_loss: 0.2906 - val_auc_4: 0.9551\n",
      "Epoch 9/100\n",
      "163/163 [==============================] - 24s 147ms/step - loss: 0.1953 - auc_4: 0.9766 - val_loss: 0.2716 - val_auc_4: 0.9566\n",
      "Epoch 10/100\n",
      "163/163 [==============================] - 24s 147ms/step - loss: 0.1758 - auc_4: 0.9810 - val_loss: 0.2930 - val_auc_4: 0.9545\n",
      "Epoch 11/100\n",
      "163/163 [==============================] - 24s 147ms/step - loss: 0.1583 - auc_4: 0.9845 - val_loss: 0.2936 - val_auc_4: 0.9567\n",
      "Epoch 12/100\n",
      "163/163 [==============================] - 24s 148ms/step - loss: 0.1465 - auc_4: 0.9866 - val_loss: 0.3272 - val_auc_4: 0.9446\n",
      "Epoch 13/100\n",
      "163/163 [==============================] - 24s 147ms/step - loss: 0.1283 - auc_4: 0.9897 - val_loss: 0.3656 - val_auc_4: 0.9505\n",
      "Epoch 14/100\n",
      "163/163 [==============================] - 24s 147ms/step - loss: 0.1223 - auc_4: 0.9905 - val_loss: 0.3325 - val_auc_4: 0.9519\n",
      "Epoch 15/100\n",
      "163/163 [==============================] - 24s 147ms/step - loss: 0.0913 - auc_4: 0.9945 - val_loss: 0.3825 - val_auc_4: 0.9428\n",
      "Epoch 16/100\n",
      "163/163 [==============================] - 24s 147ms/step - loss: 0.0858 - auc_4: 0.9948 - val_loss: 0.4022 - val_auc_4: 0.9475\n",
      "Epoch 17/100\n",
      "163/163 [==============================] - 24s 147ms/step - loss: 0.0738 - auc_4: 0.9963 - val_loss: 0.4292 - val_auc_4: 0.9442\n",
      "Epoch 18/100\n",
      "163/163 [==============================] - 24s 147ms/step - loss: 0.0727 - auc_4: 0.9963 - val_loss: 0.4217 - val_auc_4: 0.9437\n",
      "Epoch 19/100\n",
      "163/163 [==============================] - 24s 148ms/step - loss: 0.0594 - auc_4: 0.9972 - val_loss: 0.4346 - val_auc_4: 0.9443\n",
      "The val auc for fold 4, RNN_model_6 is 0.9567016181879349\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# helpers \n",
    "def train_model(model_in, test_pred_mode = False, n_folds=5):\n",
    "\n",
    "    gkf = GroupKFold(n_folds)\n",
    "    store = []\n",
    "\n",
    "    model_in.summary()\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(\n",
    "        gkf.split(train, labels, groups.unique())\n",
    "    ):\n",
    "        print(f\"Fitting fold {fold} for {model_in.name}...\")\n",
    "        model = keras.models.clone_model(model_in)\n",
    "        model.compile(\n",
    "            optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[keras.metrics.AUC()]\n",
    "        )\n",
    "\n",
    "        X_train, X_val = train[train_idx], train[val_idx]\n",
    "        y_train, y_val = labels.iloc[train_idx], labels.iloc[val_idx]\n",
    "\n",
    "        history = model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=100,\n",
    "            verbose=1,\n",
    "            batch_size=128,\n",
    "            callbacks=[\n",
    "                keras.callbacks.EarlyStopping(\n",
    "                    patience=10, monitor=\"val_loss\", restore_best_weights=True\n",
    "                )\n",
    "            ],\n",
    "        )\n",
    "        auc = roc_auc_score(y_val, model.predict(X_val).squeeze())\n",
    "        print(f\"The val auc for fold {fold}, {model_in.name} is {auc}\")\n",
    "\n",
    "        if test_pred_mode:\n",
    "            store.append(model.predict(test).squeeze())\n",
    "        else:\n",
    "            store.append(auc)\n",
    "            \n",
    "    result = sum(store) / n_folds # if test mode we want the prediction\n",
    "    return result\n",
    "\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(60, train.shape[2])),\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(512, return_sequences=True)), \n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(256, return_sequences=True)), \n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True)), \n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(64, return_sequences=True)),\n",
    "    keras.layers.Bidirectional(keras.layers.GRU(32, return_sequences=True)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(200, activation=\"swish\"),\n",
    "    keras.layers.Dense(150, activation=\"swish\"),\n",
    "    keras.layers.Dense(50, activation=\"swish\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "], name = 'RNN_model_6')\n",
    "\n",
    "\n",
    "preds = train_model(model, test_pred_mode = True)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('../Data/sample_submission.csv')\n",
    "sub['state'] = preds.round()\n",
    "sub.to_csv('../Submissions/rnn_sub.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25968</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25969</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25970</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25971</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25972</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12213</th>\n",
       "      <td>38181</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12214</th>\n",
       "      <td>38182</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12215</th>\n",
       "      <td>38183</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12216</th>\n",
       "      <td>38184</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12217</th>\n",
       "      <td>38185</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12218 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sequence  state\n",
       "0         25968    1.0\n",
       "1         25969    1.0\n",
       "2         25970    0.0\n",
       "3         25971    1.0\n",
       "4         25972    1.0\n",
       "...         ...    ...\n",
       "12213     38181    0.0\n",
       "12214     38182    1.0\n",
       "12215     38183    0.0\n",
       "12216     38184    0.0\n",
       "12217     38185    0.0\n",
       "\n",
       "[12218 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f0328b9ad2d19e2d019a5993aa83b306c7898874533c9685774e41d7ccadc38f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 ('tab22': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
